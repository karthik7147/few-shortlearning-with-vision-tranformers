{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 9667438,
          "sourceType": "datasetVersion",
          "datasetId": 5907253
        },
        {
          "sourceId": 11695829,
          "sourceType": "datasetVersion",
          "datasetId": 7340877
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "fewshort learning with vision transformers ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthik7147/few-shortlearning-with-vision-tranformers/blob/main/fewshort_learning_with_vision_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "h-9_Y0YCj8DA"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "amirberenji_thermal_images_of_induction_motor_path = kagglehub.dataset_download('amirberenji/thermal-images-of-induction-motor')\n",
        "kkaarrtthhiikkr_thermal_path = kagglehub.dataset_download('kkaarrtthhiikkr/thermal')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "BpKr6YMJj8DB"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-18T07:30:39.169354Z",
          "iopub.execute_input": "2025-04-18T07:30:39.169555Z",
          "iopub.status.idle": "2025-04-18T07:30:40.509955Z",
          "shell.execute_reply.started": "2025-04-18T07:30:39.169538Z",
          "shell.execute_reply": "2025-04-18T07:30:40.509061Z"
        },
        "id": "fb15Yvndj8DB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import timm\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# ==============================\n",
        "# Step 1: Data Augmentation (Fixed)\n",
        "# ==============================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.3),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "dataset_path = \"../input/thermal-images-of-induction-motor\"\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "train_size = int(0.85 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# ==============================\n",
        "# Step 2: Vision Transformer Model (Fixed)\n",
        "# ==============================\n",
        "class ViTModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ViTModel, self).__init__()\n",
        "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "        self.fc = nn.Linear(self.vit.head.in_features, num_classes)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.bn = nn.BatchNorm1d(self.vit.head.in_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.vit.forward_features(x)[:, 0, :]\n",
        "        x = self.bn(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes = len(dataset.classes)\n",
        "model = ViTModel(num_classes).to(device)\n",
        "\n",
        "# ==============================\n",
        "# Step 3: Extract Features (Fixed)\n",
        "# ==============================\n",
        "def extract_features(model, data_loader):\n",
        "    model.eval()\n",
        "    features, labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, lbls in data_loader:\n",
        "            images = images.to(device)\n",
        "            output = model.vit.forward_features(images)[:, 0, :]\n",
        "            features.append(output.cpu().numpy())\n",
        "            labels.append(lbls.cpu().numpy())\n",
        "\n",
        "    return np.concatenate(features), np.concatenate(labels)\n",
        "\n",
        "train_features, train_labels = extract_features(model, train_loader)\n",
        "test_features, test_labels = extract_features(model, test_loader)\n",
        "\n",
        "# ==============================\n",
        "# Step 4: Few-Shot Model (Fixed)\n",
        "# ==============================\n",
        "class FewShotClassifier(nn.Module):\n",
        "    def __init__(self, feature_dim, num_classes):\n",
        "        super(FewShotClassifier, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(feature_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "few_shot_model = FewShotClassifier(train_features.shape[1], num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(few_shot_model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "train_features = torch.tensor(train_features, dtype=torch.float32).to(device)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.long).to(device)\n",
        "\n",
        "# Train Few-Shot Classifier with Stability Fixes\n",
        "few_shot_model.train()\n",
        "for epoch in range(25):  # Increased training epochs\n",
        "    optimizer.zero_grad()\n",
        "    outputs = few_shot_model(train_features)\n",
        "    loss = criterion(outputs, train_labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    accuracy = accuracy_score(train_labels.cpu().numpy(), torch.argmax(outputs, 1).cpu().numpy())\n",
        "    print(f\"Epoch [{epoch+1}/25], Loss: {loss.item():.4f}, Train Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# ==============================\n",
        "# Step 5: Evaluate Model\n",
        "# ==============================\n",
        "test_features = torch.tensor(test_features, dtype=torch.float32).to(device)\n",
        "test_labels = torch.tensor(test_labels, dtype=torch.long).to(device)\n",
        "\n",
        "few_shot_model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = few_shot_model(test_features)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    accuracy = accuracy_score(test_labels.cpu().numpy(), predicted.cpu().numpy())\n",
        "    print(f\"âœ… Improved Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# ==============================\n",
        "# Step 6: Confusion Matrix & Report\n",
        "# ==============================\n",
        "true_labels = test_labels.cpu().numpy()\n",
        "predicted_labels = predicted.cpu().numpy()\n",
        "\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "class_report = classification_report(true_labels, predicted_labels, target_names=dataset.classes)\n",
        "\n",
        "print(\"\\nðŸ“Š Classification Report:\\n\", class_report)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"Blues\", xticklabels=dataset.classes, yticklabels=dataset.classes)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T18:43:28.207546Z",
          "iopub.execute_input": "2025-03-22T18:43:28.207866Z",
          "iopub.status.idle": "2025-03-22T18:43:36.17982Z",
          "shell.execute_reply.started": "2025-03-22T18:43:28.207841Z",
          "shell.execute_reply": "2025-03-22T18:43:36.178925Z"
        },
        "id": "OI_fcmdxj8DC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(model, few_shot_model, data_loader, num_images=5):\n",
        "    model.eval()\n",
        "    few_shot_model.eval()\n",
        "\n",
        "    images, labels = next(iter(data_loader))\n",
        "    images, labels = images[:num_images].to(device), labels[:num_images].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        features, _ = extract_features(model, [(images, labels)])\n",
        "        features = torch.tensor(features, dtype=torch.float32).to(device)\n",
        "        outputs = few_shot_model(features)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(12, 4))\n",
        "    for i in range(num_images):\n",
        "        img = images[i].cpu().permute(1, 2, 0).numpy()\n",
        "        img = (img - img.min()) / (img.max() - img.min())\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f\"Pred: {dataset.classes[preds[i]]}\\nActual: {dataset.classes[labels[i]]}\")\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_predictions(model, few_shot_model, test_loader)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T18:44:17.59133Z",
          "iopub.execute_input": "2025-03-22T18:44:17.591687Z",
          "iopub.status.idle": "2025-03-22T18:44:18.094813Z",
          "shell.execute_reply.started": "2025-03-22T18:44:17.591661Z",
          "shell.execute_reply": "2025-03-22T18:44:18.094022Z"
        },
        "id": "WNWnLyL9j8DC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(model, data_loader, num_images=5):\n",
        "    model.eval()\n",
        "\n",
        "    images, labels = next(iter(data_loader))\n",
        "    num_images = min(num_images, len(images))  # Ensure we don't exceed available samples\n",
        "    images, labels = images[:num_images].to(device), labels[:num_images].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(14, 4))\n",
        "    for i in range(num_images):\n",
        "        img = images[i].cpu().permute(1, 2, 0).numpy()\n",
        "        img = (img - img.min()) / (img.max() - img.min())  # Normalize for display\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f\"Pred: {dataset.classes[preds[i]]}\\nActual: {dataset.classes[labels[i]]}\")\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-18T07:36:50.537445Z",
          "iopub.execute_input": "2025-04-18T07:36:50.537789Z",
          "iopub.status.idle": "2025-04-18T07:36:50.543636Z",
          "shell.execute_reply.started": "2025-04-18T07:36:50.537761Z",
          "shell.execute_reply": "2025-04-18T07:36:50.542828Z"
        },
        "id": "fgtKh-Koj8DC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import timm\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# ========== 1. Augmentation ==========\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "\n",
        "dataset_path = \"../input/thermal-images-of-induction-motor\"\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "train_size = int(0.85 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# ========== 2. Full ViT Fine-tuning ==========\n",
        "class ViTClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ViTClassifier, self).__init__()\n",
        "        self.vit = timm.create_model('vit_small_patch16_224', pretrained=True, num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes = len(dataset.classes)\n",
        "model = ViTClassifier(num_classes).to(device)\n",
        "\n",
        "# ========== 3. Training Setup ==========\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "# ========== 4. Training Loop with Early Stopping ==========\n",
        "best_accuracy = 0\n",
        "patience, trigger_times = 5, 0\n",
        "\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        all_preds.extend(torch.argmax(outputs, 1).cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"Epoch [{epoch+1}/30], Loss: {total_loss:.4f}, Train Accuracy: {train_acc * 100:.2f}%\")\n",
        "\n",
        "    # Early stopping logic\n",
        "    if train_acc > best_accuracy:\n",
        "        best_accuracy = train_acc\n",
        "        trigger_times = 0\n",
        "        torch.save(model.state_dict(), \"best_vit_model.pth\")\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "# ========== 5. Evaluation ==========\n",
        "model.load_state_dict(torch.load(\"best_vit_model.pth\"))\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        all_preds.extend(torch.argmax(outputs, 1).cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_acc = accuracy_score(all_labels, all_preds)\n",
        "print(f\"\\nâœ… Final Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "# ========== 6. Report & Confusion Matrix ==========\n",
        "print(\"\\nðŸ“Š Classification Report:\\n\", classification_report(all_labels, all_preds, target_names=dataset.classes))\n",
        "\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"Blues\", xticklabels=dataset.classes, yticklabels=dataset.classes)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-18T07:32:22.411226Z",
          "iopub.execute_input": "2025-04-18T07:32:22.411567Z",
          "iopub.status.idle": "2025-04-18T07:34:07.699348Z",
          "shell.execute_reply.started": "2025-04-18T07:32:22.411547Z",
          "shell.execute_reply": "2025-04-18T07:34:07.698321Z"
        },
        "id": "p6MPpT6gj8DD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import timm\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# ============================\n",
        "# 1. Augmentation\n",
        "# ============================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "\n",
        "dataset_path = \"../input/thermal-images-of-induction-motor\"\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "train_size = int(0.85 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# ============================\n",
        "# 2. Model\n",
        "# ============================\n",
        "class ViTClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ViTClassifier, self).__init__()\n",
        "        self.vit = timm.create_model('vit_small_patch16_224', pretrained=True, num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes = len(dataset.classes)\n",
        "model = ViTClassifier(num_classes).to(device)\n",
        "\n",
        "# ============================\n",
        "# 3. Training Setup\n",
        "# ============================\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "# ---- Tracking variables ----\n",
        "loss_values = []\n",
        "train_acc_values = []\n",
        "lr_values = []\n",
        "\n",
        "# ============================\n",
        "# 4. Training Loop + Early Stopping\n",
        "# ============================\n",
        "best_accuracy = 0\n",
        "patience, trigger_times = 5, 0\n",
        "\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        all_preds.extend(torch.argmax(outputs, 1).cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(all_labels, all_preds)\n",
        "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/30], Loss: {total_loss:.4f}, Train Acc: {train_acc*100:.2f}%, LR: {current_lr}\")\n",
        "\n",
        "    # ---- Store for graphs ----\n",
        "    loss_values.append(total_loss)\n",
        "    train_acc_values.append(train_acc)\n",
        "    lr_values.append(current_lr)\n",
        "\n",
        "    # ---- Early Stopping ----\n",
        "    if train_acc > best_accuracy:\n",
        "        best_accuracy = train_acc\n",
        "        trigger_times = 0\n",
        "        torch.save(model.state_dict(), \"best_vit_model.pth\")\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "# ============================\n",
        "# 5. Evaluation\n",
        "# ============================\n",
        "model.load_state_dict(torch.load(\"best_vit_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        all_preds.extend(torch.argmax(outputs, 1).cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_acc = accuracy_score(all_labels, all_preds)\n",
        "print(f\"\\nâœ… Final Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "# ============================\n",
        "# 6. Classification Report + Confusion Matrix\n",
        "# ============================\n",
        "print(\"\\nðŸ“Š Classification Report:\\n\", classification_report(all_labels, all_preds, target_names=dataset.classes))\n",
        "\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"Blues\",\n",
        "            xticklabels=dataset.classes, yticklabels=dataset.classes)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ============================\n",
        "# 7. Training Graphs\n",
        "# ============================\n",
        "\n",
        "# ---- Loss Curve ----\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(loss_values, marker='o')\n",
        "plt.title(\"Training Loss Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ---- Accuracy Curve ----\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot([acc * 100 for acc in train_acc_values], marker='o')\n",
        "plt.title(\"Training Accuracy Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ---- Learning Rate Curve ----\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(lr_values, marker='o')\n",
        "plt.title(\"Learning Rate Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-04T06:50:14.3088Z",
          "iopub.execute_input": "2025-12-04T06:50:14.30917Z",
          "iopub.status.idle": "2025-12-04T06:52:30.302179Z",
          "shell.execute_reply.started": "2025-12-04T06:50:14.309141Z",
          "shell.execute_reply": "2025-12-04T06:52:30.301317Z"
        },
        "id": "zKQlvaa_j8DD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================\n",
        "# 3 GRAPHS IN ONE FIGURE\n",
        "# ============================\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "# ---- 1. Training Loss Curve ----\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(loss_values, marker='o')\n",
        "plt.title(\"Training Loss Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "\n",
        "# ---- 2. Training Accuracy Curve ----\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot([acc * 100 for acc in train_acc_values], marker='o')\n",
        "plt.title(\"Training Accuracy Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.grid(True)\n",
        "\n",
        "# ---- 3. Learning Rate Curve ----\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(lr_values, marker='o')\n",
        "plt.title(\"Learning Rate Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-04T06:58:43.163136Z",
          "iopub.execute_input": "2025-12-04T06:58:43.163501Z",
          "iopub.status.idle": "2025-12-04T06:58:43.697378Z",
          "shell.execute_reply.started": "2025-12-04T06:58:43.163456Z",
          "shell.execute_reply": "2025-12-04T06:58:43.696536Z"
        },
        "id": "iHCYk2t7j8DD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(model, data_loader, num_images=10):\n",
        "    model.eval()\n",
        "\n",
        "    images, labels = next(iter(data_loader))\n",
        "    images, labels = images[:num_images].to(device), labels[:num_images].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    # ---- Create 2 rows Ã— 5 columns ----\n",
        "    rows, cols = 2, 5\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(16, 7))\n",
        "\n",
        "    idx = 0\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if idx >= num_images:\n",
        "                axes[r][c].axis('off')\n",
        "                continue\n",
        "\n",
        "            img = images[idx].cpu().permute(1, 2, 0).numpy()\n",
        "            img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "            axes[r][c].imshow(img)\n",
        "            axes[r][c].set_title(\n",
        "                f\"Pred: {dataset.classes[preds[idx]]}\\nActual: {dataset.classes[labels[idx]]}\",\n",
        "                fontsize=10\n",
        "            )\n",
        "            axes[r][c].axis('off')\n",
        "            idx += 1\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-04T07:04:15.995071Z",
          "iopub.execute_input": "2025-12-04T07:04:15.995395Z",
          "iopub.status.idle": "2025-12-04T07:04:16.001902Z",
          "shell.execute_reply.started": "2025-12-04T07:04:15.995367Z",
          "shell.execute_reply": "2025-12-04T07:04:16.001019Z"
        },
        "id": "yIWGcVKnj8DD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(model, test_loader, num_images=10)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-04T07:04:20.451294Z",
          "iopub.execute_input": "2025-12-04T07:04:20.451634Z",
          "iopub.status.idle": "2025-12-04T07:04:21.590007Z",
          "shell.execute_reply.started": "2025-12-04T07:04:20.451607Z",
          "shell.execute_reply": "2025-12-04T07:04:21.589125Z"
        },
        "id": "Q8kqHiAYj8DE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import timm\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# ============================\n",
        "# 1. Augmentation\n",
        "# ============================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "\n",
        "dataset_path = \"../input/thermal-images-of-induction-motor\"\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "# ---- Train / Val / Test split ----\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size   = int(0.15 * len(dataset))\n",
        "test_size  = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    dataset, [train_size, val_size, test_size]\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# ============================\n",
        "# 2. Model\n",
        "# ============================\n",
        "class ViTClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.vit = timm.create_model(\n",
        "            'vit_small_patch16_224',\n",
        "            pretrained=True,\n",
        "            num_classes=num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes = len(dataset.classes)\n",
        "model = ViTClassifier(num_classes).to(device)\n",
        "\n",
        "# ============================\n",
        "# 3. Training Setup\n",
        "# ============================\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
        "\n",
        "# ---- Tracking ----\n",
        "train_loss_vals, val_loss_vals = [], []\n",
        "train_acc_vals, val_acc_vals = [], []\n",
        "lr_vals = []\n",
        "\n",
        "# ============================\n",
        "# 4. Training Loop (Early Stop on VAL ACC)\n",
        "# ============================\n",
        "best_val_acc = 0\n",
        "patience, trigger = 5, 0\n",
        "\n",
        "for epoch in range(30):\n",
        "    # -------- TRAIN --------\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_preds, train_labels = [], []\n",
        "\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    # -------- VALIDATION --------\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_preds, val_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_acc = accuracy_score(val_labels, val_preds)\n",
        "\n",
        "    # ---- Store ----\n",
        "    train_loss_vals.append(train_loss)\n",
        "    val_loss_vals.append(val_loss)\n",
        "    train_acc_vals.append(train_acc)\n",
        "    val_acc_vals.append(val_acc)\n",
        "    lr_vals.append(optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/30] | \"\n",
        "          f\"Train Acc: {train_acc*100:.2f}% | \"\n",
        "          f\"Val Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "    # ---- Early Stopping ----\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        trigger = 0\n",
        "        torch.save(model.state_dict(), \"best_vit_model.pth\")\n",
        "    else:\n",
        "        trigger += 1\n",
        "        if trigger >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "# ============================\n",
        "# 5. Testing\n",
        "# ============================\n",
        "model.load_state_dict(torch.load(\"best_vit_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "test_preds, test_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        test_preds.extend(outputs.argmax(1).cpu().numpy())\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_acc = accuracy_score(test_labels, test_preds)\n",
        "print(f\"\\nâœ… Final Test Accuracy: {test_acc*100:.2f}%\")\n",
        "\n",
        "# ============================\n",
        "# 6. Report + Confusion Matrix\n",
        "# ============================\n",
        "print(\"\\nðŸ“Š Classification Report\\n\",\n",
        "      classification_report(test_labels, test_preds, target_names=dataset.classes))\n",
        "\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\",\n",
        "            xticklabels=dataset.classes,\n",
        "            yticklabels=dataset.classes)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# ============================\n",
        "# 7. ONE FIGURE â€“ 3 GRAPHS\n",
        "# ============================\n",
        "epochs = range(1, len(train_loss_vals)+1)\n",
        "\n",
        "plt.figure(figsize=(18,5))\n",
        "\n",
        "# ---- Loss ----\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(epochs, train_loss_vals, label=\"Train Loss\")\n",
        "plt.plot(epochs, val_loss_vals, label=\"Val Loss\")\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# ---- Accuracy ----\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(epochs, [a*100 for a in train_acc_vals], label=\"Train Acc\")\n",
        "plt.plot(epochs, [a*100 for a in val_acc_vals], label=\"Val Acc\")\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# ---- Learning Rate ----\n",
        "plt.subplot(1,3,3)\n",
        "plt.plot(epochs, lr_vals)\n",
        "plt.title(\"Learning Rate Schedule\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"LR\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-24T09:27:51.800424Z",
          "iopub.execute_input": "2025-12-24T09:27:51.800917Z",
          "iopub.status.idle": "2025-12-24T09:29:41.336001Z",
          "shell.execute_reply.started": "2025-12-24T09:27:51.80089Z",
          "shell.execute_reply": "2025-12-24T09:29:41.335201Z"
        },
        "id": "8HfYtW7Lj8DE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, len(train_loss_vals)+1)\n",
        "\n",
        "plt.figure(figsize=(18,5))\n",
        "\n",
        "# ---- Loss ----\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(epochs, train_loss_vals, label=\"Train Loss\")\n",
        "plt.plot(epochs, val_loss_vals, label=\"Val Loss\")\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# ---- Accuracy ----\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(epochs, [a*100 for a in train_acc_vals], label=\"Train Acc\")\n",
        "plt.plot(epochs, [a*100 for a in val_acc_vals], label=\"Val Acc\")\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-24T09:40:55.828665Z",
          "iopub.execute_input": "2025-12-24T09:40:55.828985Z",
          "iopub.status.idle": "2025-12-24T09:40:56.467408Z",
          "shell.execute_reply.started": "2025-12-24T09:40:55.828962Z",
          "shell.execute_reply": "2025-12-24T09:40:56.466587Z"
        },
        "id": "rwdT3qZPj8DE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18, 5))  # wider figure\n",
        "\n",
        "# ---- Loss ----\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(epochs, train_loss_vals, label=\"Train Loss\", linewidth=2)\n",
        "plt.plot(epochs, val_loss_vals, label=\"Val Loss\", linewidth=2)\n",
        "plt.title(\"Loss Curve\", fontsize=20)\n",
        "plt.xlabel(\"Epoch\", fontsize=18)\n",
        "plt.ylabel(\"Loss\", fontsize=18)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.tick_params(axis='both', which='major', labelsize=12)\n",
        "\n",
        "# ---- Accuracy ----\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(epochs, [a*100 for a in train_acc_vals], label=\"Train Accuracy\", linewidth=2)\n",
        "plt.plot(epochs, [a*100 for a in val_acc_vals], label=\"Validation Accuracy\", linewidth=2)\n",
        "plt.title(\"Accuracy Curve\", fontsize=20)\n",
        "plt.xlabel(\"Epoch\", fontsize=18)\n",
        "plt.ylabel(\"Accuracy (%)\", fontsize=18)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.tick_params(axis='both', which='major', labelsize=12)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-24T09:44:19.126206Z",
          "iopub.execute_input": "2025-12-24T09:44:19.126517Z",
          "iopub.status.idle": "2025-12-24T09:44:19.531966Z",
          "shell.execute_reply.started": "2025-12-24T09:44:19.126496Z",
          "shell.execute_reply": "2025-12-24T09:44:19.531047Z"
        },
        "id": "LYyhq3F_j8DE"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}